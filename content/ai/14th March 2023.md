+++
title =  "Generative AI Group Chat: Hackathon and Alpaca AI"
date = 2023-03-14T00:00:00+05:30
tags = ["daily_summary"]
featured_image = ""
description = "A group chat discussing a hackathon with prize money and evaluation criteria, as well as exploring Alpaca AI's capabilities, pricing, and comparison to other AI models. The conversation also touches on the challenges of keeping up with rapid developments in the AI space."
toc = true
+++

## Introduction
- Group chat discussing Generative AI
- Non-techie member seeking help to keep up with the discussion

## Participants
- [PHONE REMOVED] [PHONE REMOVED] [PHONE REMOVED] are PMs
- [PHONE REMOVED] [PHONE REMOVED] are founder and VC respectively
- [PHONE REMOVED] is Mumbai based creative agency person
- Manjot [PHONE REMOVED] is with Lightspeed VC currently

## Hackathon
- Prize money split is 1L minimum per track, split between all members of the winning team equally
- Evaluation criteria is left to the jury's discretion
- Some members prefer leaving the criteria to the judges while others prefer having a clear set of criteria
- Tracks are announced for the hackathon

## Alpaca AI
- https://alpaca-ai-custom4.ngrok.io/ is slow to try prompts
- It looks more like davinci-002 than the 003 series in terms of ability to follow logic over multiple hops
- No weights, so it's iffy on what is going inside training
- The instruct dataset is key
- The PR they have raised with Huggingface gives you the training code
- Built for enterprise
- 3x the price of other AI models
- 12 cents per 1K token completions is quite expensive
- GPT4 capabilities have a FOSS counterpart from Amazon: github.com/amazon-science/mm-cot

## Miscellaneous
- Too much happening in this space in a day, difficult to keep up with things
- Be My Eyes demo is hilarious
- IST timing is odd for some members
- Thank you for adding me to the community

## Links
The description and link can be mismatched because of extraction errors.

- https://alpaca-ai-custom4.ngrok.io/ - The message discusses the slow performance of the website for trying prompts and compares its ability to follow logic to the davinci-002 series. It also mentions uncertainty about the training process due to the lack of weights.
- https://twitter.com/OpenAI/status/1635687373060317185?t=nhm2BaNejunBE9-syFgEeA&s=19 - The tweet mentions that the instruct dataset is key and provides a link to the PR raised with Huggingface for the training code. It also suggests that the project is built for enterprise.
- https://www.youtube.com/live/outcGtbnMuQ?feature=share - The message mentions the "be my eyes demo" being hilarious and thanks someone, but also notes odd timing and waiting for a summary from others.