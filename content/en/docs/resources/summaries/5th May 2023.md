---
contributors:
- Nirant Kasliwal
date: '2023-05-05 00:00:00+05:30'
description: Discussing the competitive landscape between OpenAI and Google models,
  Hugging Face's StarCoder LLM launch, and generative models' probabilistic functions.
  Also touching on resources available on Amazon's mm-CoT, determinism in GPT, and
  various AI tools and platforms.
draft: false
excerpt: Discussing the competitive landscape between OpenAI and Google models, Hugging
  Face's StarCoder LLM launch, and generative models' probabilistic functions. Also
  touching on resources available on Amazon's mm-CoT, determinism in GPT, and various
  AI tools and platforms.
featured_image: ''
images: []
lastmod: '2023-05-05 00:00:00+05:30'
tags:
- daily_summary
title: OpenAI, Google Models, and Hugging Face Developments
toc: true
weight: 50
---

OpenAI and Google models:
- Google models have no moat
- OpenAI may have a moat due to early mover advantage and alignment with Microsoft/Azure
- OpenAI's moat may come from government and finance domains
- OpenAI may be able to maintain its lead for 2 to 5 years or more
- Open source models are far behind OpenAI currently, but may catch up eventually
- Network effects may not be a moat in this case
- Microsoft+OpenAI can make inference costs low and onboard other businesses on plugins

Hugging Face:
- StarCoder LLM launched
- Good intro + inference optimizations on Diffusers shared by Huggingface folks at NVIDIA-HF Meet-up
- Resources for SoTA large models in multimodal space (text, image, video, audio, etc) available on Amazon's mm-CoT on HF and PapersWithCode

Generative models:
- Probabilistic functions in generative models may be pseudo-random and can be controlled via seed
- Rate limits for models may be shared or separate
- Determinism can be achieved by fixing the seeding of the model or setting temperature=0
- Randomness in GPT comes from the probability distribution over the vocabulary
- Meta's SAM and Track Anything can be used for tracking logos from video
- So-vits-svc is a good tool for replicating AI songs

Other:
- Discord server with a lot of models available
- SlackGPT is a horizontally integrated business workflow with Slack
- MPT-7B-Instruct checkpoint used for ChatGPT, but may not do well with code understanding
- Wandb.ai has prompts for generating text.

## Links
The description and link can be mismatched because of extraction errors.

- Microsoft is investing in AMD to counter Nvidia GPU monopoly and developing custom inference GPUs to make inference costs low, which could make hosting other LLMs unnecessary unless there are compliance issues. This is part of Microsoft's efforts to commoditize their complement. The information is shared in the link https://gwern.net/complement, which also discusses the potential implications of this strategy.
- https://www.semianalysis.com/p/google-we-have-no-moat-and-neither: The message in the same link as the URL is related to the link, which talks about Google's lack of a competitive advantage. The context of the message is unclear, but it mentions missing a week.
- https://docs.google.com/presentation/d/1cbcP-wpeb3jMS4-20cEKFmNJAObg13Q_JNbl0YV6qyU/edit#slide=id.g20f09001284_0_76 - Good intro + inference optimisations on Diffusers shared by Huggingface folks at NVIDIA-HF Meet-up.
- The URL https://agi-sphere.com/llama-models/ is mentioned in relation to So-vita-svc and so-vits-svc.
- https://discord.gg/aihub - A link to a Discord server with a community of 7000 people discussing models and cutting-edge work. The message also praises the community's focus and productivity, with a shoutout to [PHONE REMOVED].
- https://discord.gg/aihub: A link to a Discord server with a community of 7000 people discussing models and cutting-edge work, with praise for the community manager.
- The URL https://wandb.ai/site/prompts is being shared/discussed in the group and the message suggests that it may not have been shared before.