{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70c7d2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "058b3b57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Datetime</th>\n",
       "      <th>Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-03-01 14:28:13</td>\n",
       "      <td>Please leave a one line intro when you join an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-03-01 14:29:24</td>\n",
       "      <td>I'm Pranjal Mehta. Cofounded ePlane.ai (electr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-03-01 14:29:26</td>\n",
       "      <td>Hey folks,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-03-01 14:29:50</td>\n",
       "      <td>I'm Nirant K. ML/LLM Consultant out of BLR. Mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-03-01 14:30:27</td>\n",
       "      <td>Hey</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Datetime                                            Message\n",
       "0  2023-03-01 14:28:13  Please leave a one line intro when you join an...\n",
       "1  2023-03-01 14:29:24  I'm Pranjal Mehta. Cofounded ePlane.ai (electr...\n",
       "2  2023-03-01 14:29:26                                        Hey folks, \n",
       "3  2023-03-01 14:29:50  I'm Nirant K. ML/LLM Consultant out of BLR. Mo...\n",
       "4  2023-03-01 14:30:27                                                Hey"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../20230505_Messages.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9fc49eb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Looks like @919619491715 got a DM from our benevolent dictator ðŸ˜‚, welcome to the group'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Message\"][21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2a210b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Group by week\n",
    "df[\"Datetime\"] = pd.to_datetime(df[\"Datetime\"])\n",
    "df['Week'] = df['Datetime'].dt.isocalendar().week\n",
    "df['Date'] = df['Datetime'].dt.date\n",
    "\n",
    "# Group by Date\n",
    "daily_df = df.groupby('Date').agg({'Message': ' \\n '.join}).reset_index()\n",
    "daily_df = pd.DataFrame(daily_df)\n",
    "len(daily_df)\n",
    "\n",
    "# # Group by Week\n",
    "# weekly_df = df.groupby('Week').agg({'Message': ' \\n '.join}).reset_index()\n",
    "# weekly_df = pd.DataFrame(messages_df)\n",
    "# print(weekly)\n",
    "# print(weekly_df[\"Message\"][9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "655b8858",
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_df[\"wc\"] = daily_df[\"Message\"].apply(lambda x: len(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c8296bd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count      63.000000\n",
       "mean      900.492063\n",
       "std       727.693703\n",
       "min         8.000000\n",
       "25%       286.500000\n",
       "50%       695.000000\n",
       "75%      1498.000000\n",
       "max      2540.000000\n",
       "Name: wc, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily_df[\"wc\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "77948434",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import OpenAI, PromptTemplate, LLMChain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.chains.mapreduce import MapReduceChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "\n",
    "from functools import lru_cache\n",
    "llm = ChatOpenAI(temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "370e4415",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = CharacterTextSplitter.from_tiktoken_encoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "5c8699fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Integration of chatGPT/LLMs into smart home devices\n",
      "- Query about integration of chatGPT/LLMs into Alexa/Nest type of smart home devices\n",
      "- Mention of tools that can do it, but openai key is a barrier to adoption\n",
      "\n",
      "## Paddlespeech\n",
      "- Query about anyone dabbling with paddlespeech\n",
      "\n",
      "## ChatGPT talk by Anil Ananthaswamy\n",
      "- Video of the talk by Anil Ananthaswamy on ChatGPT held at BIC is published\n",
      "- Link: https://youtu.be/WF28ZwhUCc4\n",
      "\n",
      "## Automatic1111 and DrawThings App\n",
      "- Use of Automatic1111 on colab\n",
      "- Recommendation to download DrawThings App on MacBook\n",
      "- Suggestion to try smaller models for GPU memory issue\n",
      "- Mention of Jay trying to get it running on local via Web GPU\n",
      "- Image generation on windows took a lot of time\n",
      "- Automatic1111 works well on Mac for simple text2image, but may have trouble with complex operations\n",
      "- Mention of text-to-video taking off in the future\n",
      "\n",
      "## MacBook and generative AI capabilities\n",
      "- Discussion on buying a MacBook for generative AI capabilities\n",
      "- Recommendation to either go all the way or get the Macbook air\n",
      "- Suggestion to get as big of a machine as wallet permits for local gen AI capabilities\n",
      "- Mention of M1 MB-air being plenty if there is a cloud setup\n",
      "- Query about how optimized the models are for running on apple RAM as opposed to Nvidia GPUs\n",
      "\n",
      "## Serverless Vector DB and pricing\n",
      "- Discussion on serverless Vector DB and pricing around it\n",
      "- Link: https://twitter.com/jobergum/status/1644653416994488320\n",
      "- Mention of it being a free masterclass on Developer eXperience and how that influences pricing, GTM\n",
      "- Link to a related video: https://youtu.be/8y7GRYaYYQg\n",
      "\n",
      "## GPT assisting game development\n",
      "- Discussion on GPT assisting game development\n",
      "- Mention of a demo where the dev is debugging the logic on his own, but letting GPT4 fix the syntax and API calls\n",
      "- Expectation of dedicated planning \"agents\" which can pair with the dev much more on the first part within 2-3 months\n",
      "- Query about hearing more from game devs\n",
      "\n",
      "## Podcast style fireside chat/discussion\n",
      "- Interest in participating in a podcast style fireside chat/discussion\n",
      "- Mention of working on something close to it\n",
      "CPU times: user 11.8 ms, sys: 3.56 ms, total: 15.3 ms\n",
      "Wall time: 5.45 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "class SummarizeDay:\n",
    "    def __init__(self, plain_text):\n",
    "        self.prompt_template = \"\"\"This is a chaotic Generative AI Group Chat transcript. Write detailed, exhaustive bullet point recap of topics discussed. Extract COMPLETE URL of web and social links with context. Please organise it into sections, only when needed:\n",
    "\n",
    "{text}\n",
    "\n",
    "\n",
    "Use Markdown. Add ## for section titles. TOPICS RECAP:\"\"\"\n",
    "# Research with weblinks where relevant EXACTLY ONCE:\n",
    "        self.PROMPT = PromptTemplate(template=self.prompt_template, input_variables=[\"text\"])\n",
    "#         self.chain = load_summarize_chain(ChatOpenAI(temperature=0), chain_type=\"map_reduce\", return_intermediate_steps=True, map_prompt=PROMPT, combine_prompt=PROMPT)\n",
    "        self.chain = load_summarize_chain(ChatOpenAI(temperature=0), chain_type=\"stuff\", prompt=self.PROMPT)\n",
    "        self.docs = self.make_docs(plain_text)\n",
    "        \n",
    "    @lru_cache\n",
    "    def make_docs(self, plain_text: str):\n",
    "        texts = text_splitter.split_text(plain_text)\n",
    "        docs = [Document(page_content=t) for t in texts]\n",
    "        return docs\n",
    "\n",
    "    def summarize_docs(self):   \n",
    "        chain_output = self.chain({\"input_documents\": self.docs}, return_only_outputs=True)\n",
    "        return chain_output\n",
    "\n",
    "plain_text = daily_df[\"Message\"][36]\n",
    "sd = SummarizeDay(plain_text)\n",
    "chain_output = sd.summarize_docs()\n",
    "output_text = chain_output[\"output_text\"]\n",
    "print(output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "8d7bea92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- https://twitter.com/Mascobot/status/1651022921056555008?t=3qozUieRAPdsnScv3XnQLw&s=19 - The tweet mentions that something was built in under 2 weeks and discusses the differences between Codex iterations and vanilla LLM, including GPT3.5-turbo and GPT4.\n",
      "- https://www.reddit.com/r/StableDiffusion/comments/12yzd2a/google_researchers_achieve_performance/ - Discussion thread on ML on edge computing, with a mention of Stanford NLP.\n",
      "- https://www.qualcomm.com/news/onq/2023/02/worlds-first-on-device-demonstration-of-stable-diffusion-on-android: Some earlier work from Qualcomm, \"Wow!\"\n",
      "- PSA: Dedicated group for music, images, video: https://chat.whatsapp.com/GThJJhoF3cL7QCmrfIoY8J\n",
      "- https://twitter.com/matthieurouif/status/1650904940036890626 - A Twitter post discussing the availability of an API for the GPT-4 multimodal model.\n",
      "- https://minigpt-4.github.io/ or https://llava-vl.github.io/ - These URLs can be used instead of Photoroom as it doesn't have image understanding.\n",
      "- https://minigpt-4.github.io/ or https://llava-vl.github.io/ - These URLs can be used instead of Photoroom as it doesn't have image understanding.\n",
      "- https://dust.tt: The message states that the website is awesome and currently internal.\n",
      "- https://www.linkedin.com/posts/genai-center_ai-generated-pizza-commercial-tools-used-activity-7056952600516046848-mvqm?utm_source=share&utm_medium=member_ios - A post about using AI to generate a pizza commercial and mentioning tools used. The user @917054124184 is mentioned as playing with music generation.\n",
      "- https://www.paperspace.com - suggested as an option for GPU storage by the message sender in the context of experimenting with StableDiffusion and running Gradio/Automatic1111, and needing storage of around 50GB.\n",
      "- https://research.google.com/colaboratory/marketplace.html: Connect a GCE VM to Colab for persistent sessions and dedicated compute. Runpod is recommended to stop the instance when not in use to only be charged for storage.\n",
      "- https://www.chartgpt.dev/ - This website may provide information about non persistent/spot instances of GPUs that were in under supply during testing.\n",
      "- https://news.ycombinator.com/item?id=35697627 - This news article may provide additional context or discussion about the shortage of non persistent/spot instances of GPUs during testing.\n",
      "- https://www.chartgpt.dev/ : This is a link to a website, with no further context provided.\n",
      "- https://news.ycombinator.com/item?id=35697627 : This is a link to a discussion thread on Hacker News, where someone is asking a question about using Weaviate and storing metadata.\n",
      "- https://www.youtube.com/watch?v=7TCqGslll-4: A video related to embedding content in an app.\n",
      "- https://github.com/ai-forever/Kandinsky-2: A GitHub repository, possibly related to containerization.\n",
      "- https://www.youtube.com/watch?v=7TCqGslll-4: This link leads to a YouTube video.\n",
      "- https://github.com/ai-forever/Kandinsky-2: This link leads to a GitHub repository for Kandinsky-2 by ai-forever.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "WINDOW = 1\n",
    "def extract_urls_with_context(text):\n",
    "    lines = text.split('\\n')\n",
    "    url_pattern = re.compile(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+')\n",
    "    urls_with_context = []\n",
    "\n",
    "    for idx, line in enumerate(lines):\n",
    "        for match in url_pattern.finditer(line):\n",
    "            start, end = match.span()\n",
    "            prev_line = lines[idx - WINDOW] if idx > 0 else \"\"\n",
    "            next_line = lines[idx + WINDOW] if idx < len(lines) - 1 else \"\"\n",
    "            context = f\"{prev_line}\\n{line}\\n{next_line}\".strip()\n",
    "            urls_with_context.append((match.group(), context))\n",
    "\n",
    "    return urls_with_context\n",
    "\n",
    "\n",
    "    urls_with_context = extract_urls_with_context(url)\n",
    "    for url, context in urls_with_context:\n",
    "        print(f\"URL: {url}\")\n",
    "        print(f\"Context: {context}\\n\")\n",
    "        \n",
    "\n",
    "\n",
    "class LinksContext:\n",
    "    def __init__(self, plain_text):\n",
    "        self.prompt_template = \"\"\"For each URL, there is some context. Newlines may or may not be related to the link, but the message in the same link as link is related to the link.\n",
    "        \n",
    "{text}\n",
    "        \n",
    "Mention URL with context. Single bullet point:\"\"\"\n",
    "# Research with weblinks where relevant EXACTLY ONCE:\n",
    "        self.PROMPT = PromptTemplate(template=self.prompt_template, input_variables=[\"text\"])\n",
    "#         self.chain = load_summarize_chain(ChatOpenAI(temperature=0, model_name=\"gpt-4\"), chain_type=\"map_reduce\", return_intermediate_steps=True, map_prompt=PROMPT, combine_prompt=PROMPT)\n",
    "        self.chain = load_summarize_chain(ChatOpenAI(temperature=0), chain_type=\"stuff\", prompt=self.PROMPT)\n",
    "        self.docs = self.make_docs(plain_text)\n",
    "        \n",
    "    @lru_cache\n",
    "    def make_docs(self, plain_text: str):\n",
    "        texts = text_splitter.split_text(plain_text)\n",
    "        docs = [Document(page_content=t) for t in texts]\n",
    "        return docs\n",
    "\n",
    "    def summarize_docs(self):   \n",
    "        chain_output = self.chain({\"input_documents\": self.docs}, return_only_outputs=True)\n",
    "        return chain_output\n",
    "\n",
    "plain_text = daily_df[\"Message\"][54]\n",
    "url_groups = extract_urls_with_context(plain_text)\n",
    "for ug in url_groups:\n",
    "    lc = LinksContext(ug[1])\n",
    "    chain_output = lc.summarize_docs()\n",
    "    output_text = chain_output[\"output_text\"]\n",
    "    print(output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972a576a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
